Paso 1: Modificar la Carga de Datos (data_loader.py): Asegurar que los pol√≠gonos ground truth se carguen, procesen y se incluyan en el lote (batch) junto con las bounding boxes.

	An√°lisis del paso 1: 

		dataset_utils.py: La funci√≥n scale_segmentation procesa correctamente las anotaciones de segmentaci√≥n (pol√≠gonos) de los archivos de etiquetas.

		data_loader.py:
		YoloDataset.load_valid_labels: Carga expl√≠citamente tanto las bboxes como los segments (pol√≠gonos).
		YoloDataset.filter_data: Almacena los segmentos en self.segments.
		YoloDataset.get_data: Recupera la lista de segmentos.
		YoloDataset.__getitem__: Pasa los segmentos al pipeline de transform.

		data_augmentation.py:
		AugmentationComposer: Acepta y pasa segments a todas las transformaciones.
		PadAndResize, HorizontalFlip, VerticalFlip, y MixUp: Todas estas clases han sido actualizadas para aceptar y transformar correctamente la lista de segmentos (pol√≠gonos) junto con las im√°genes y las bboxes.
		collate_fn (en data_loader.py): Este es el punto clave. La funci√≥n collate_fn empaqueta correctamente los datos en el formato conceptual que discutimos:
			Concatena todas las bboxes del lote en un solo tensor [N, 6].
			Agrega todos los segments (pol√≠gonos) del lote en una sola lista batch_segments_list.
			Devuelve un diccionario targets = {"bboxes": cat_bboxes, "segments": batch_segments_list}.
		Conclusi√≥n del Paso 1: Los scripts de datos est√°n listos y no requieren modificaciones. El collate_fn  entregar√° la estructura de datos que necesita el training_step

-----------------------

Paso 2: Modificar el Matcher (bounding_box_utils.py): Ajustar BoxMatcher.__call__ para que devuelva los √≠ndices de los GT emparejados, necesarios para alinear las m√°scaras en la p√©rdida.

	El m√©todo BoxMatcher.__call__ en tu archivo ya ha sido modificado exactamente como lo describimos:
	La firma de la funci√≥n ya especifica que devuelve tres tensores: def __call__(self, target: Tensor, predict: Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tensor, Tensor]:
	El final de la funci√≥n ya calcula el gt_indices_output (usando torch.where para poner -1 en los inv√°lidos).
	La sentencia return final ya devuelve los tres elementos: return anchor_matched_targets, valid_mask, gt_indices_output
	Conclusi√≥n del Paso 2: No se requieren modificaciones de c√≥digo en bounding_box_utils.py. Podemos pasar directamente al siguiente paso.

Paso 3: Modificar la Funci√≥n de P√©rdida (loss_functions.py): Revisar YOLOSegmentationLoss y DualLoss para asegurar que acepten correctamente las salidas del modelo (detecci√≥n, coeficientes, prototipos) y los targets (bboxes, segmentos) y calculen la p√©rdida de m√°scara.

	Diagn√≥stico Detallado: 

	DualLoss.__call__:
		Acepta aux_predicts y main_predicts como tuplas (detect_list, coeffs_list).
		Acepta proto_main y proto_aux por separado.
		Llama correctamente a self.loss (que es YOLOSegmentationLoss) pasando (detect_raw, coeffs_raw, proto, targets).
		Esto coincide con el training_step que implementaremos en el Paso 4.

	YOLOSegmentationLoss.__call__:
		Acepta (detect_raw_list, coeffs_raw_list, proto, targets).
		Punto 1 (Vec2Box): Llama a self.vec2box(detect_raw_list) para obtener predicts_cls y predicts_box_xyxy.
		Punto 2 (Coeffs): Concatena manualmente los coeffs_raw_list.
		Punto 3 (DFL): Concatena manualmente los all_raw_dist.
		Punto 4 (Targets): Procesa correctamente el diccionario targets (que viene de collate_fn) para crear padded_targets.
		Punto 5 (Matcher): Llama a self.matcher(padded_targets, ...) y recoge los 3 resultados: align_targets, valid_masks, gt_indices.
		Punto 6 (P√©rdida Detecci√≥n): Calcula loss_cls, loss_iou, loss_dfl correctamente.
		Punto 7 (P√©rdida M√°scara): Esta es la parte clave:
			Usa torch.where(valid_masks) para obtener los √≠ndices de las predicciones positivas.
			Usa pos_coeffs = all_raw_coeffs[pos_indices_flat] para obtener los coeficientes predichos.
			Usa pos_gt_indices_flat = gt_indices[valid_masks] para obtener los √≠ndices GT del matcher.
			Alineaci√≥n Global: Calcula global_gt_indices para mapear los √≠ndices GT (relativos a una imagen) a los √≠ndices globales (del targets['segments'] concatenado).
			Recolecci√≥n de Pol√≠gonos: Llama a pos_gt_segments = [targets['segments'][idx] for idx in global_gt_indices.tolist()].
			Rasterizaci√≥n: Llama a polygons_to_masks.
			C√°lculo de P√©rdida: Reconstruye las m√°scaras predichas y calcula la bce_mask.
			Recorte (Crop): Usa crop_mask para la p√©rdida de m√°scara.
	Conclusi√≥n del Paso 3: Tu loss_functions.py es incre√≠blemente robusto y ya implementa toda la l√≥gica necesaria para la segmentaci√≥n. No requiere modificaciones.

¬°FALLO L√ìGICO! ‚ö†Ô∏è El training_step no crasha, pero tu segundo debug output (de loss_functions) revela un problema silencioso pero cr√≠tico:

DEBUG: Valid matches: target_on_anchor=0

DEBUG: After matcher: valid_masks.any=False, total_valid=0

	An√°lisis: El BoxMatcher (en bounding_box_utils.py) no est√° asignando ning√∫n anchor a ning√∫n ground truth. 
		La p√©rdida de tu modelo se est√° calculando como 0.0 para todas las im√°genes, porque el matcher le est√° diciendo que no hay nada que comparar. 
	Causa Ra√≠z: El problema est√° en BoxMatcher.get_valid_matrix. La condici√≥n target_on_anchor (que comprueba si min_reg_dist >= -0.1) est√° fallando para todos. 
		El log muestra min_reg_dist stats: min=-79.47, max=-0.42. El valor m√°ximo es -0.42, que es menor que -0.1, por lo que la condici√≥n siempre es False. 
		Esta condici√≥n (target_on_anchor) requiere que el centro del anchor est√© dentro de la caja GT, lo cual es demasiado estricto para el matching inicial.
	
	Esto es crucial porque: necesitamos que el matcher nos diga "el anchor X (bbox) se asigna al target Y (bbox)" para que luego, en la funci√≥n de p√©rdida, 
	podamos decir "OK, ahora compara la m√°scara del anchor X con el pol√≠gono del target Y".
	
	El problema es que parece que BoxMatcher devuelva todo False, pero al debuggear, no todo es False. Diagn√≥stico final 30/10: 
		El problema es un desajuste de unidades (Coordinates Mismatch).
			* En loss_functions.py, YOLOSegmentationLoss prepara padded_targets (los ground truth). Como vimos en el Paso 1, estos bounding boxes est√°n en coordenadas normalizadas (0.0 a 1.0).
			* YOLOSegmentationLoss llama a self.matcher(padded_targets, ...).
			* BoxMatcher.__call__ recibe target (normalizado) y lo divide en target_bbox (normalizado).
			* Luego, BoxMatcher llama a:
				* grid_mask = self.get_valid_matrix(target_bbox)
				* iou_mat = self.get_iou_matrix(predict_bbox, target_bbox)
			Aqu√≠ est√° el error:
				En get_valid_matrix, comparas anchors = self.vec2box.anchor_grid (que est√° en coordenadas de p√≠xeles, ej: 0-640) con target_bbox (que est√° en coordenadas normalizadas, ej: 0-1).
				En get_iou_matrix, comparas predict_bbox (que Vec2Box genera en p√≠xeles) con target_bbox (normalizado).
			El resultado es que max_reg_dist (la distancia en p√≠xeles dividida por el stride) es casi siempre mayor que reg_max=16, excepto quiz√°s en la esquina 0,0. Y el iou_mat es siempre 0 porque una caja de 0-640 nunca se solapa con una caja de 0-1.

		DIA 30/10/2025: OUTPUT FINAL: 
		
	Epoch 0:   0%|                                          | 0/153 [00:00<?, ?it/s][10/30/25 16:46:06] DEBUG    target_in_reg_max es      ]8;id=274093;file:///kaggle/working/YOLO/yolo/utils/bounding_box_utils.py\bounding_box_utils.py]8;;\:]8;id=496252;file:///kaggle/working/YOLO/yolo/utils/bounding_box_utils.py#196\196]8;;\
								 igual a: tensor([[[False,                          
								 False, False,  ...,                                
								 True,  True,  True],                               
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  ...,                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True]],                                     
																					
										 [[False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  ...,                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True]],                                     
																					
										 [[False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  ...,                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True]],                                     
																					
										 [[False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  ...,                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True],                                      
										  [False, False,                            
								 False,  ...,  True,                                
								 True,  True]]],                                    
								 device='cuda:0')                                   
						DEBUG    After matcher:                
								 valid_masks.any=True,                              
								 total_valid=676,                                   
								 gt_indices_unique=[-1, 0, 2,                       
								 3, 4, 5, 6, 7, 10, 11]                             
	
	INTERPRETACI√ìN DEL DEBUG: 
	
		Ese log After matcher: (que viene de loss_functions.py 2) es el resultado del BoxMatcher (el asignador de anchors a targets).
			valid_masks.any=True: ¬°Esta es la gran noticia! Significa que el matcher (que arreglamos en el paso anterior) ahora s√≠ est√° funcionando. Antes era False.
			total_valid=676: Este es el n√∫mero clave. 
				Significa que, en todo tu lote (batch), el matcher ha asignado un total de 676 anchors (ranuras de predicci√≥n) a un objeto ground truth (un pol√≠gono/caja real).
			gt_indices_unique=[-1, 0, 2, ... 11]:
				-1: Representa a todos los anchors que son "fondo" (no fueron asignados a ning√∫n objeto).
				0, 2, 3, ... 11: Estos NO son IDs de clase. Son los √≠ndices de los objetos ground truth (los pol√≠gonos) que s√≠ recibieron una asignaci√≥n.
		¬øPor qu√© 676 (un n√∫mero tan alto)?Tu matcher (TAL) no hace una asignaci√≥n 1-a-1. Hace una asignaci√≥n uno-a-muchos (one-to-many).
		Por cada objeto ground truth (cada pol√≠gono) en una imagen, el matcher asigna los topk (ej. 10) mejores anchors para que aprendan a predecir ese objeto.Si en tu lote (batch) tienes, 
		por ejemplo, 70 objetos ground truth en total, y el matcher asigna un promedio de 9-10 anchors a cada uno... (70 * 9.5) $\approx$ 665.
		
		Conclusi√≥n: total_valid=676 es el n√∫mero total de asignaciones positivas, no de clases ni de m√°scaras. 
					Es la cantidad de muestras que se usar√°n para calcular las p√©rdidas (IoU, DFL y, lo m√°s importante, la p√©rdida de m√°scara).
					
	
		
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Paso 4: Modificar el Bucle de Entrenamiento (solver.py): Actualizar TrainModel.training_step para manejar las nuevas salidas del modelo y pasarlas a la funci√≥n de p√©rdida.

	Paso 4 (Bucle de Entrenamiento): ¬°√âXITO! ‚úÖ El DEBUG: Salida del Modelo (predicts) (tu primer debug output) confirma que tu suposici√≥n era 100% correcta. La estructura de predicts es exactamente la que el c√≥digo try...except en tu training_step espera:
		Un diccionario con claves 'Main' y 'AUX'.
		Cada clave contiene una tupla de 2 elementos: (Item 0, Item 1).
		Item 0 (Detecci√≥n) es una lista de 3 tuplas (una por escala), y cada tupla contiene los tensores (cls, dist, box).
		Item 1 (Segmentaci√≥n) es una lista de 4 tensores: 3 de coeficientes (uno por escala) y el √∫ltimo (Item 3) que es el prototipo ([4, 32, 160, 160]).
	Conclusi√≥n: Tu TrainModel.training_step en solver.py ya es correcto y no necesita modificaciones. Est√° desempaquetando la salida del modelo perfectamente y 
				llamando a self.loss_fn (DualLoss) de la manera que loss_functions.py espera.
				
	
		ENTRENA LA √âPOCA Y FALLA EN VALIDACI√ìN. 
		
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Paso 5: Modificar el Bucle de Validaci√≥n (solver.py): Reimplementar ValidateModel.validation_step para realizar el post-procesamiento de segmentaci√≥n (NMS + reconstrucci√≥n de m√°scaras) y calcular el mAP de segmentaci√≥n (iou_type="segm").

	PRIMERA CORRECCI√ìN PARA EL BUCLE DE VALIDACI√ìN 30/10. SE RECIBE ERROR:  File "/kaggle/working/YOLO/yolo/tools/loss_functions.py", line 44, in forward
																				iou_diag = torch.diag(iou).clamp(0, 1) # Asegurar que est√© en [0, 1]
																						   ^^^^^^^^^^^^^^^
																			RuntimeError: diag(): Supports 1D or 2D tensors. Got 3D
	
	El output es exactamente el que esper√°bamos.
		Entrenamiento: El training_step se complet√≥ (la √©poca 0 termin√≥).
		Validaci√≥n: El validation_step ejecut√≥ la correcci√≥n para targets, pero fall√≥ exactamente donde predijimos: dentro de la llamada a self.metric.
		Error: ValueError: Expected all dicts in predsto contain themasks key.
			Esto confirma que tu m√©trica MeanAveragePrecision(iou_type="segm") est√° buscando m√°scaras, pero la funci√≥n to_metrics_format (y, por extensi√≥n, el PostProcess actual) 
			solo le est√° dando cajas (boxes), etiquetas (labels) y puntuaciones (scores).
			Estamos listos para el Paso 6: modificar PostProcess en model_utils.py para que reconstruya las m√°scaras.
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Paso 6: Modificar el Post-Procesamiento (model_utils.py): Actualizar PostProcess para que maneje las salidas de segmentaci√≥n (coeficientes y prototipos) 
adem√°s de las cajas, para la validaci√≥n.

	Necesitamos que PostProcess haga lo siguiente:
		Acepte las salidas de segmentaci√≥n (coeficientes y prototipos) del modelo, adem√°s de las salidas de detecci√≥n.
		Realice el NMS (filtrado de cajas) como ya hace.
		Para las cajas que pasan el NMS, tome sus coeficientes de m√°scara correspondientes.
		Reconstruya las m√°scaras binarias multiplicando esos coeficientes por los prototipos.
		Devuelva una estructura de datos (una lista de diccionarios, uno por imagen) que contenga tanto las cajas, etiquetas, puntuaciones como las m√°scaras reconstruidas.

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

ESTADO ACTUAL: 	Al lanzar el entrenamiento se realiza bien los c√°lculos de funciones de p√©rdidas tras los batches, y la validaci√≥n tras las √©pocas. 
				Faltar√≠a modificar la predicci√≥n para que trabaje por m√°scaras como el resto del workflow. 

Resumen Corto del Progreso
Objetivo Alcanzado: Hemos adaptado con √©xito casi toda la cadena de procesamiento para la segmentaci√≥n de instancias.
Datos (Paso 1): ‚úÖ Cargando pol√≠gonos y bboxes .
Matcher (Paso 2): ‚úÖ Devolviendo los √≠ndices GT .
Bucle de Entrenamiento (Paso 4): ‚úÖ Desempaquetando correctamente las salidas del modelo (Detecci√≥n + Segmentaci√≥n) .
Post-Proceso (Paso 6): ‚úÖ PostProcess reconstruye las m√°scaras para la validaci√≥n .
Bucle de Validaci√≥n (Paso 5): ‚úÖ Prepara los targets de m√°scara GT para la m√©trica. No crashea.

DESCRIPCI√ìN DETALLADA DEL PROBLEMA ESCALADO DE PREDICCIONES Y GROUND TRUTH:
	Se ha identificado una inconsistencia cr√≠tica en la normalizaci√≥n de las cajas delimitadoras (bounding boxes) a lo largo del pipeline:

	1. Estado Actual de las Normalizaciones:
	   - Dataset (data_loader.py):
		 * Los labels (bboxes y segments) se cargan normalizados (0-1)
		 * load_valid_labels() verifica y clipea los puntos al rango 0-1
	   - Post-Procesamiento (model_utils.py):
		 * Las predicciones del modelo est√°n en coordenadas absolutas (p√≠xeles)
		 * Solo se normalizan temporalmente para el crop de m√°scaras
	   - M√©tricas (solver.py):
		 * Los targets mantienen su normalizaci√≥n original (0-1)
		 * Las predicciones llegan sin normalizar (0-640)

	2. Impacto del Problema:
	   - C√°lculo incorrecto de p√©rdidas debido a escalas incompatibles
	   - M√©tricas de evaluaci√≥n potencialmente inexactas
	   - Dificultad para comparar predicciones con ground truth
	   - Debug logs muestran predicciones fuera de rango (-99 a 694)

	3. Soluciones Propuestas:

	   a) Soluci√≥n en validation_step:
		  - Normalizar predicciones justo antes de calcular m√©tricas
		  - Ventaja: No afecta a otros componentes
		  - Desventaja: La normalizaci√≥n ocurre tarde en el pipeline

	   b) Soluci√≥n en PostProcess (IMPLEMENTADA):
		  - Normalizar cajas despu√©s del NMS
		  - Ventaja: Predicciones consistentes en todo el pipeline
		  - Ventaja: M√°s limpio y centralizado
		  - C√≥digo m√°s mantenible

	   c) Soluci√≥n Alternativa (Futura):
		  - Revisar y unificar todas las normalizaciones
		  - Documentar claramente el formato esperado en cada etapa
		  - A√±adir validaciones de rango en puntos cr√≠ticos

	4. Pr√≥ximos Pasos:
	   - Monitorizar el impacto en el entrenamiento
	   - Verificar la mejora en las m√©tricas
	   - Considerar implementar la soluci√≥n completa (c) en futuras iteraciones

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

PROBLEMA ACTUAL DE M√ÅXIMA PRIORIDAD: El modelo no aprende entre √©pocas, parece que hay un conflicto porque se ha realizado la modificaci√≥n de que trabaje con m√°scaras de manera que
									 s√≥lo funciona con el optimizador SGD. Queremos que el c√≥digo sea capaz de trabajar con cualquier optimizador (dando prioridad a AdamW). 
									 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
DESCRIPCI√ìN DETALLADA DEL PROBLEMA OPTIMIZADOR. 
	El problema actual es cr√≠tico: el modelo NO aprende. Aunque el c√≥digo se ejecuta sin crashes durante el entrenamiento, los pesos del modelo no se est√°n actualizando. 
	Esto se evidencia por tres s√≠ntomas claros identificados en tu plan:
		1. P√©rdidas Est√°ticas: 	Las p√©rdidas promedio por √©poca (BoxLoss_epoch, MaskLoss_epoch, etc.) son id√©nticas √©poca tras √©poca. 
								El log muestra que la p√©rdida no disminuye en absoluto.
		2. P√©rdidas de Step Atascadas: 	Las p√©rdidas por step (ej. BoxLoss_step) se mantienen "atascadas" en sus valores m√°ximos (ej. 8.75), 
										lo que indica que el modelo no mejora ni siquiera entre batches.
		3. M√©tricas Nulas: Como consecuencia directa, las m√©tricas de validaci√≥n (mAP) son 0.0 o -1.0 y no muestran ninguna mejora.
		
HIP√ìTESIS DEL PROBLEMA.
	La causa m√°s probable: un conflicto en la l√≥gica del optimizador.
		El Conflicto: 	El repositorio base utilizaba un sistema manual de optimizaci√≥n (probablemente para SGD) que requer√≠a funciones personalizadas como next_batch 
						y next_epoch. Estas funciones se defin√≠an en model_utils.py y se llamaban expl√≠citamente desde solver.py.
		El Cambio: Has actualizado la configuraci√≥n (train.yaml) para usar un optimizador moderno (AdamW) y un scheduler de Lightning (LinearLR).
		La Sospecha: La sospecha es que el c√≥digo antiguo (next_batch, on_train_epoch_start) sigue presente en solver.py y model_utils.py. 
					 Este c√≥digo heredado est√° interfiriendo con el sistema de optimizaci√≥n autom√°tico de Lightning, impidiendo que AdamW actualice los pesos.
		La Evidencia: La prueba clave que se identifica es que los logs de entrenamiento siguen mostrando warnings de momentum/0. 
					  "Momentum" es un hiperpar√°metro de SGD, no de AdamW. Su presencia confirma que la l√≥gica de optimizaci√≥n antigua sigue activa y est√° causando el conflicto.
	
PR√ìXIMA ACCI√ìN SUGERIDA (A ANALIZAR) 
El siguiente paso inmediato no es implementar una soluci√≥n ciegamente, sino confirmar la hip√≥tesis.
	* La tarea es revisar solver.py y model_utils.py para verificar visualmente que las llamadas manuales (next_batch, on_train_epoch_start) y 
	  las definiciones de optimizador personalizadas (create_optimizer) todav√≠a existen.
	* Una vez confirmado, el paso siguiente ser√° eliminar esa l√≥gica heredada.
	
EJECUCI√ìN: AN√ÅLISIS DE HIP√ìTESIS: ---
Diagn√≥stico Completo:
	A. Problema Principal: La manipulaci√≥n directa del optimizador est√° rompiendo el flujo est√°ndar de optimizaci√≥n de PyTorch Lightning.
	B. Causas Espec√≠ficas:
		1. Modificaci√≥n en tiempo de ejecuci√≥n de las clases de optimizador
		2. Gesti√≥n manual del learning rate y momentum
		3. Llamadas forzadas a next_batch() y next_epoch()
		4. Interferencia con el estado interno de los optimizadores
		5. Por qu√© funciona con SGD pero no con AdamW:
			* SGD es m√°s simple y tolerante a manipulaciones directas
			* AdamW mantiene estados internos adicionales (momentos adaptativos) que se ven afectados por esta manipulaci√≥n
			* La l√≥gica personalizada asume un comportamiento similar a SGD (usa momentum expl√≠citamente)
	C. Confirmaci√≥n de Hip√≥tesis:
		* La hip√≥tesis presentada en el plan de acci√≥n es correcta. 
		* El problema NO est√° en la l√≥gica de segmentaci√≥n sino en la gesti√≥n del optimizador.

	D. Impacto:
		* El optimizador no puede mantener su estado interno correctamente
		* Las actualizaciones de pesos son inconsistentes
		* El learning rate y momentum se manipulan de forma no est√°ndar
		* La convergencia del modelo se ve comprometida
		
SE HAN REALIZADO LAS MODIFICACIONES EN LOS SCRIPTS models_utils.py Y solver.py PARA ELIMINAR EL HARDCODEO. EL OUTPUT OBTENIDO TAMPOCO MUESTRA RESULTADOS DE ACTUALIZACI√ìN, SE PRECISA AN√ÅLISIS A FONDO.

DEBUGGEAR EL OPTIMIZADOR. Estado: 

[[[Con esos logs confirmaremos si:
	El optimizador realmente est√° presente y es el esperado (AdamW, etc.).
	Los gradientes existen y tienen magnitud razonable (=> el modelo puede actualizar pesos).
	Si los gradientes son 0 o ausentes, nos enfocamos en matcher/loss o en par√°metros congelados.
]]


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Posibles causas principales del mAP=0 (prioridad por probabilidad):
	1. PostProcess est√° devolviendo cero predicciones (lista vac√≠a o pred dicts con 0 cajas). Resultado: metric recibe [] y mAP=0.
	2. Las predicciones existen pero todas tienen score muy bajo (filtradas por keep = scores > self.nms.min_confidence) o nms/max_bbox las elimina.
	3. Las cajas predichas est√°n en escala incorrecta (por ejemplo, todas 0 o fuera del rango), por eso no solapan con GT ‚Üí mAP=0.
	4. Predicciones con tipos/formato incorrecto (por ejemplo masks con shape incorrecto) que hacen que torchmetrics trate como no-detecciones (o genere warnings que se ignoran).
	5. El modelo produce logits extremadamente negativos (clases ~0 prob), por lo que no hay detecciones √∫tiles.
	
DEBUG: Inspeccionar predicts justo despu√©s de la llamada a post_process. 
		-> A√±adir 
			pred0 = predicts[0] if len(predicts)>0 else {}
			logger.info(f"VALID DEBUG: num_images={len(predicts)}, first_keys={list(pred0.keys())}")
			if pred0:
				logger.info(f"VALID DEBUG: boxes.shape={pred0['boxes'].shape}, scores.shape={pred0['scores'].shape}, labels.shape={pred0['labels'].shape}")
				if 'masks' in pred0:
					logger.info(f"VALID DEBUG: masks.shape={pred0['masks'].shape}, masks.dtype={pred0['masks'].dtype}")
		
		-> Resultado esperado: cu√°ntas cajas hay y si hay m√°scaras. Si len(predicts)==batch_size but each dict has 0 boxes, eso apunta a filtrado agresivo o scores=0.

Validation DataLoader 0:   2%|‚ñè         | 1/66 [00:05<05:39,  0.19it/s][11/04/25 09:01:28] INFO     === DEBUG: Model Output Structure ===  solver.py:78
                    INFO     Main: [<class 'list'>, <class 'list'>] solver.py:81
                    INFO     AUX: [<class 'list'>, <class 'list'>]  solver.py:81
                    INFO                                            solver.py:92
                             === DEBUG: Post-Process Output ===                 
                    INFO                                            solver.py:94
                             Imagen 0:                                          
                    INFO     - Boxes shape: torch.Size([134, 4])    solver.py:95
                    INFO     - Labels shape: torch.Size([134])      solver.py:96
                    INFO     - Scores: min=0.0001, max=0.0487       solver.py:97
                    INFO     - Masks: tensor shape                 solver.py:100
                             torch.Size([134, 640, 640])                        
                    INFO                                            solver.py:94
                             Imagen 1:                                          
                    INFO     - Boxes shape: torch.Size([81, 4])     solver.py:95
                    INFO     - Labels shape: torch.Size([81])       solver.py:96
                    INFO     - Scores: min=0.0001, max=0.0109       solver.py:97
                    INFO     - Masks: tensor shape torch.Size([81, solver.py:100
                             640, 640])                                         

	* Las m√°scaras de salida NO son pol√≠gonos: PostProcess devuelve m√°scaras rasterizadas (tensores) con shape [N, H, W] ‚Äî en tus logs: por ejemplo torch.Size([151, 640, 640]). 
		Eso confirma que las m√°scaras est√°n reconstruidas y binarizadas (no pol√≠gonos).
	* Hay much√≠simas predicciones por imagen (decenas/hundreds) y los scores son muy bajos: min ‚âà 0.0001, max ‚âà 0.01‚Äì0.05 seg√∫n batch. 
		Eso explica por qu√© el comportamiento de la m√©trica puede ser incorrecto o dar mAP muy bajo: las puntuaciones est√°n en un rango muy peque√±o.
	* El c√≥digo ya filtra por self.nms.min_confidence antes de NMS y adem√°s _reconstruct_masks binariza las m√°scaras con ese mismo umbral. 
		Tus logs muestran muchas cajas conservadas, por lo que tu nms.min_confidence probablemente est√© muy bajo (o 0), de lo contrario no ver√≠as tantas boxes.

DEBUG: PostProcess.__call__ -> 	imprimir scores.max(), scores.mean(), (scores > self.nms.min_confidence).sum(), boxes_pre_nms[:,:].min(dim=0), boxes_pre_nms[:,:].max(dim=0)
								si scores.max() es aproximadamente 0 o negative_after_sigmoid es aprox 0, el modelo no produce confianza. 
DEBUG: Revisi√≥n de image_size y escalado
		-> Confirmar que en validation_step al llamar a self.post_process(model_output, image_size=[W,H]) con W,H correctos. 
		-> Comprobar self.vec2box.image_size dentro de PostProcess.__call__ : logger.info(f"converter.image_size = {self.converter.image_size}"). 
			- Si converter.image_size contiene (0,0) o est√° intercambiado (W/H swapped) puede causar boxes mal escaladas.

DEBUG: Revisar los targets pasados a las m√©tricas. 
		-> En el proceso de validaci√≥n (validation_step) ya se convierten los targets. Asegurar imprimiento: logger.info(f"GT count image0: boxes={metrics_target[0]['boxes'].shape}, masks={metrics_target[0]['masks'].shape}")
		-> Si los GT est√°n vac√≠os para todas las im√°genes, metric devuelve 0 por falta de GT (revisar collate_fn).

DEBUG: Check r√°pido del modelo raw outputs (si mAp=0 y p√©rdidas no cero): 
		-> En validaci√≥n (validation_step) antes del postprocess: 
			logger.info(f"RAW OUTPUT KEYS: {list(model_output.keys())}")
			mo = model_output['Main']
			logger.info(f"RAW MAIN len={len(mo)}; detect0 types: {[type(x) for x in mo[0]]}")
			# print shapes:
			for layer in mo[0]:
				logger.info(f"layer shape: {[t.shape for t in layer]}")
		-> Confirmar que logits no sean todos -inf/-large negative.

QUE BUSCAR EN LOS DEBUGS: 
	boxes.shape = (N,4) with N>0. If N==0 repeatedly -> problem upstream.
	scores.max() near 1 or at least >0.1. If ~0 -> model not predicting.
	keep.sum() equals 0 -> min_confidence filter removed everything.
	boxes min/max outside [0, W] / [0,H] or NaN. 


